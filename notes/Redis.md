# Redis
<!-- GFM-TOC -->
* [Redis数据结构](#redis数据结构)
    * [Redis是什么](#redis是什么)
    * [Redis是单线程还是多线程](#redis是单线程还是多线程)
* [Redis持久化](#redis持久化)
    * [Redis的核心主流程](#redis的核心主流程)
<!-- GFM-TOC -->

## Redis数据结构

### 为什么使用缓存
- 使用缓存是为了提高用户体验以及应对更多的用户
- 高性能、高并发

### Redis是什么
- Redis是C语言开发的开源的高性能键值对的内存数据库，可以用作数据库、缓存、消息中间件等。端口号6379
- 它是一种非关系型数据库，性能优秀，单进程单线程，是线程安全的，采用IO多路复用机制，丰富的数据类型，支持string、list、hash、set、sorted sets等。支持数据持久化，可以将内存中数据保存到磁盘中，重启时加载。主从复制、哨兵、高可用。可以用作分布式锁，可以作为消息中间件使用，支持发布订阅。

### Redis是单线程还是多线程
- Redis4.0之前，redis是完全的单线程，这里的单线程指的是与客户端交互完成命令请求和回复的工作线程。
- Redis4.0引入了多线程，但是额外的线程只能用于后台处理，记录删除对象，异步删除、集群数据同步，核心流程还是完全单线程的。(核心线程指的是Redis正常处理客户端请求的流程，包括接受命令，解析命令，执行命令，返回结果等。**Redis的网络IO和键值对读写是由一个线程来完成的**，这也是Redis对外提供键值存储服务的主要流程)
- Redis6.0 这次引入的多线程的概念会涉及到核心线程。**多线程主要用于网络I/O阶段，也就是接收命令和写回结果阶段，而在执行命令阶段，还是由单线程串行执行。**(Redis中的多线程组不会同时存在读和写，这个多线程组只会同时读或者同时写)

### Redis6.0加入多线程I/O之后，处理命令的核心流程如下：
- 当有读事件到来时，主线程将客户端连接放到全局等待读队列
- 读取数据：1）主线程将等待读队列的客户端连接通过轮询调度算法分配给I/O线程处理；2）同时主线程也会自己负责处理一个客户端连接的读事件。3）当主线程处理完该连接的读事件后，会自旋等到所有I/O线程处理完毕
- 命令执行：**主线程按照事件被加入全局等待读队列的顺序，串行执行客户端命令，然后将客户端连接放到全局等待写队列。**这里是单线程的，也就是主线程的。
- 写回结果：跟等待读队列处理类似，将等待写队列的客户端连接放入到全局等待写队列中，然后将等待读队列的客户端连接通过轮询调度算法分配给I/O线程处理，同时自己也会处理一个。当主线程处理完毕之后，会自旋等待I/O线程处理了完毕，然后清空队列。


### 为什么Redis是单线程
- redis是完全基于内存操作的，通常情况下CPU不会成为redis的瓶颈，redis的瓶颈最可能是机器内存的大小或网络带宽。既然CPU不会成为瓶颈，就使用单线程就好了，使用多线程会更复杂，同时需要引入上下文切换、加锁等等，会带来额外的性能消耗。单线程编程容易并且更容易维护。
- 6.0版本对核心流程引入了多线程，主要用于解决redis在网络I/O上的性能瓶颈，而对核心命令的执行，还是单线程。


### Redis为什么使用单线程、单线程也很快
- 基于内存的操作
- 使用I/O多路复用模型，select，epoll等，基于reactor模式开发了自己的网络事件处理器
- 单线程避免了不必要的上下文切换和竞争条件，减少了这方面的性能消耗。
- 以上三点是主要原因，还有一些小优化，对数据结构进行了优化，简单动态字符串、压缩列表等。


### Redis在项目中的使用场景
- 缓存、分布式锁、排行榜(zset)、计数(incrby)、消息队列(stream)、地理位置(geo)、访客统计(hyperloglog)等。

---

### Redis常见的数据结构
- String(简单动态数组SDS)、List、Hash、Set、Sorted Set：有序集合，Set的基础上加了个分值
- Hyperloglog，通常用于基数统计。使用少量固定大小的内存，来统计集合中唯一的元素的数量。统计结果不是精确值，适用于对于统计结果精度要求不是特别高的场景，例如网站的UV统计。
- Geo：可以将用户给定的地理位置信息存储起来，并对这些信息进行操作：获取2个位置的距离，根据给定地理位置坐标获取指定范围内的地理位置集合。
- Bitmap：位图
- Stream：主要用于消息队列，提供消息的持久化和主备复制功能，可以让任何客户端访问任何时刻的数据，并且能记住每一个客户端的访问位置，还能保证消息不丢失。

### 为什么会设计redisObject对象
- 类型的命令检查和多态
- 对象共享

### SDS的底层实现结构
#### raw 和 embstr 的区别 
- embstr编码是专门保存短字符串的一种优化编码。
- embstr和raw都使用redisObject和sds保存数据，区别在于，embstr的使用只分配一次内存空间(embstr和redisObject是连续的)，而raw需要分配两次内存空间(分别为redisObject和sds分配空间)。因此与raw相比，embstr的好处在于创建时少分配一次内存空间，删除时少释放一次内存空间，以及对象的所有数据连在一起，寻找方便。而embstr的坏处也很明显，如果字符串的长度增加需要分配内存时，整个redisObject和sds都需要重新分配空间，因此redis中的embstr实现为只读。

### Redis的字符串(SDS)和C语言的字符串的区别
- 获取字符串长度的复杂度不同
    C语言获取长度的复杂度是O(n)，redis是O(1)
- API安全级别不同
    C语言API是不安全的，可能会造成缓冲区溢出，SDS的API是安全的，不会造成缓冲区溢出
- 修改字符串需要的内存重分配次数不同
    C语言修改字符串N次必须需要N次内存重分配，SDS最多需要N次内存重分配，SDS采用空间预分配和惰性空间释放两种策略。
- 保存数据的格式不同
    C语言只能保存文本数据，SDS可以保存文本数据和二进制数据
- 对于string.h库的使用不同
    C语言可以使用所有的库函数，SDS只能使用一部分库中的函数

### Sorted Set底层数据结构
- Sorted Set(有序集合)：ziplist/(skiplist+ht)
- ziplist：使用压缩列表实现，当保存的元素都小于64字节，同时数量小于128时，使用该编码方式，否则使用(skiplist+ht)。这两个参数可以通过zset-max-ziplist-enties、zset-max-ziplist-value来自定义修改。
- skiplist：zset实现，一个zset同时包含一个字典和一个跳跃表。

### Sorted Set为什么同时使用字典和跳跃表
- 主要是为了性能。
- 单独使用字典：在执行范围内操作，如zrank、zrange，字典需要排序，至少需要O(nlogn)的时间复杂度和额外的O(N)的内存空间。
- 单独使用跳跃表：根据成员查找分值操作的复杂度从O(1)上升为O(nlogn)。


### Sorted Set为什么使用跳跃表而不是红黑树
- 跳跃表更容易实现和调试
- 在范围查找时，平衡树比跳表操作要复杂。平衡树上，在找到指定范围的小值之后，还需要中序遍历继续寻找不超过最大值的节点。
- 平衡树的插入和删除操作可能引起子树的调整，逻辑复杂，而跳表的插入和删除操作只需要修改相邻节点的指针。
- 在内存占用上，平衡树每个节点至少需要2个指针，而跳表每个节点包含的指针数目平均为1/(1-p)，像Redis里实现的一样，p=1/4，平均每个节点包含1.33个指针


### Hash的底层实现结构

### Hash对象底层结构
- Hash对象有两种编码：ziplist、hashtable
- ziplist：使用压缩列表实现，每当有新的键值对加入到hash对象中时，会先将键的节点先压入压缩列表的表尾，接着将键的值压入压缩列表的表尾。这样的话保存了同一键值对的两个节点总是紧挨在一起，保存键的节点在前，保存值的节点在后。先进的键值对被放到压缩列表的表头，后进的被放到表尾。
- hashtable：使用字典作为底层实现，哈希对象中的每个键值对都使用一个字典键值来保存。

### Hash对象的扩容流程
- Hash对象在扩容的时候使用了一种叫渐进式rehash方式
1. 计算新表size，掩码，为新表ht[1]分配空间，让字典同时持有ht[0]和ht[1]两个哈希表。
2. 将rehash索引计数器变量rehashidx的值设为0，表示rehash开始。
3. 在rehash期间，每次对字典执行添加、删除、查找、更新操作时，程序除了执行指定的操作以外，还会出发额外的rehash操作。该方法会从ht[0]表的rehashidx索引位置上开始向后查找，找到第一个不为空的索引位置，然后将该索引位置上的所有节点rehash到ht[1]，当本次rehash工作完成之后，将ht[0]的rehashidx位置清空，同时将rehashidx属性的值加一。
4. 将rehash分摊到每个操作上，redis除了文件事件外，还有时间事件，redis会定期触发时间事件，这些时间事件用于执行一些后台操作，其中就包括rehash操作；当redis发现有字典正在进行rehash操作时，会花费1毫秒的时候，帮助进行rehash。
5. 随着操作的进行，当ht[0]的所有键值对都被rehash到ht[1]，此时rehash流程完成，会执行最后的清理工作：释放ht[0]的空间、将ht[0]指向ht[1]、重置ht[1]、重置rehashidx的值为-1。

### 渐进式rehash的优点
- 采取分而治之的方式，将rehash键值对所需的计算工作均摊到对字典的每个添加、删除、查找和更新操作上，从而避免了集中式rehash而带来的庞大计算量。
- 在渐进式rehash过程中，字典会同时使用ht[0]和ht[1]两个哈希表，所以在渐进式rehash进行期间，字典的删除、更新、查找等操作会在两个哈希表中进行。
- 在渐进式rehash期间，新增的键值对会被直接保存到ht[1]，ht[0]不再进行任何添加操作，这样就保证了ht[0]包含的键值对数量只减不增，并随着rehash操作的执行最终变成空表。

### rehash流程在数据量大的时候会有什么问题
1. 扩容开始期间，会先给ht[1]分配空间，所以在整个扩容期间，会同时存在ht[0]和ht[1]，会占用额外的空间。
2. 扩容期间同时存在ht[0]和ht[1]，查找、删除、更新操作等有概率同时操作两张表，耗时会增加。
3. redis在内存使用接近maxmemory并且有设置驱逐策略的情况下，出现rehash会使得内存占用超过maxmemory，触发驱逐淘汰操作，导致maste/slave均有大量的key被驱逐淘汰，从而出现master/slave主从不一致。

---

## Redis持久化

### Redis的核心主流程
- 最重要的两个事件：文件事件和时间事件。Redis在服务器初始化后，会无限循环，处理产生的文件事件和时间事件。
- 文件事件最常见的：接收连接、读取、写入、关闭连接。
- 时间事件常见的是serverCon，Redis默认设置100ms会被触发一次，在该时间事件中，会执行很多操作：清理过期键、AOF后台重写、RDB的save point的检查、将aof_buf内容写入磁盘，rehash


### Redis的持久化机制有哪几种
- RDB、AOF、混合持久化

### RDB触发方式

#### 手动触发
- save命令和bgsave命令

#### 自动触发

### RDB的实现原理、优缺点 
- 实现原理：类似于快照，在某个时间点上，**将Redis在内存中的数据库状态(数据库的键值对等信息)保存到磁盘里面**。RDB持久化生成的RDB文件是经过压缩的二进制文件。
- 有两个命令来用于生成RDB文件，SAVE和BGSAVE。使用save point来配置，当满足save point的时候就会触发BGSAVE来生成RDB文件。
- 注释掉所有的save point配置可以关闭RDB持久化。在save point配置后增加save “”，可以删除所有之前的save point。
- SAVE：生成RDB快照文件，但是会阻塞主线程，服务器无法处理客户端发来的命令请求。BGSAVE：fork子线程来生成RDB快照文件，阻塞之后在fork子线程的时候，之后主线程可以正常处理请求。
- RDB优点：
  - RDB文件是经过压缩的二进制文件，占用内存空间很小，它保存了Redis某个时间点的数据集，很适合用于做备份。
  - RDB非常适用于灾后恢复：它只有一个文件，并且内容十分紧凑，可以将它传送到别的数据中心。
  - RDB最大化redis的性能。父进程在保存RDB文件时唯一要做的就是fork一个子进程，然后这个子进程处理接下来的保存工作，父进程无需执行任何的磁盘I/O操作。
  - RDB在恢复大数据集时的速度比AOF的恢复速度要快。
- RDB的缺点：
  - RDB保存的是整个数据集的状态，它是一个比较重的操作，如果操作太频繁，可能会对redis的性能产生很大的影响。
  - RDB保存时使用fork子进程进行数据的持久化，如果数据比较大时，fork可能会非常耗时，造成redis停止处理服务N毫秒。
  - linux fork采用的时候copy-on-write的方式。Redis在执行RDB持久化期间，如果client写入数据频繁，将会增加Redis占用的内存。刚fork的时候，父进程和子进程共享内存，随着父进程处理写操作，主进程需要将修改的页面copy一份出来进行修改操作。极端情况下，如果所有的页面都需要修改，则此时的内存占用是原来的2倍。
  - RDB文件是二进制的，没有可读性，AOF在了解其结构的情况下可以手动修改或者补全。

- **由于生产环境中我们为Redis开辟的内存区域都比较大（例如6GB），那么将内存中的数据同步到硬盘的过程可能就会持续比较长的时间，而实际情况是这段时间Redis服务一般都会收到数据写操作请求。那么如何保证数据一致性呢？**
RDB的核心思路是Copy-on-Write，保证在进行快照操作的这段时间，需要压缩写入磁盘的数据在内存不会发生变化。在正常的快照操作中，主线程会fork一个子线程进行持久化操作，另一方面，在这段时间内发生的数据变化会存放到另一个新的内存区域，待快照结束后才会同步到原来的空间区域中。

- **频繁做全量快照，会带来两方面的消耗：**
    - 给磁盘带来很大的压力。频繁的进行全量快照，多个快照竞争磁盘资源，另一个快照还没做完，另一个又来了。
    - 会频繁阻塞主线程。虽然fork出子线程后不会阻塞主线程，但是fork这个过程本身需要阻塞主线程，而且主线程的内存越大，阻塞的时间越长。


### AOF的实现原理、优缺点
- **保存Redis服务器所执行的所有写操作命令来记录数据库状态**。并在数据库重启时，通过重新执行这些命令来还原数据集。
- AOF持久化功能的实现分为三个步骤：**命令追加、文件写入、文件同步。**
- 命令追加：当AOF持久化功能打开时，服务器执行完一个命令后，会将执行的命令追加到服务器状态的缓冲区的末尾。
- 文件写入和文件同步：linux为了提升性能，使用了页缓存(page cache)。当我们将aof缓冲区中的数据写入磁盘时，此时数据并没有真正的落盘，而是在page cache中，为了将页缓存中的数据真正的落盘，需要执行某些命令来执行强制落盘。文件同步就是文件刷盘操作。
- AOF的优点：
  - AOF比RDB可靠。我们在设置刷盘指令时，默认是everysec，在这种配置下，即使服务器宕机，也只是丢失了一秒钟的数据。
  - AOF是纯追加的日志文件。即使日志因为某些原因而包含了未写入完整的命令，也能通过工具轻易的修复这种问题。
  - 当AOF文件太大时，Redis会进行AOF重写，重写后的AOF文件包含了恢复当前数据的最小命令集合。整个重写是安全的，重写是在新文件上进行的，重写完后，Redis会把新旧文件进行替换，开始把数据写到新文件上。
  - AOF文件有序的保存了对数据库执行的所有写入操作以Redis协议的格式保存，十分容易被人读懂和分析。
- AOF的缺点：
  - 对于相同的数据集，AOF文件比RDB文件大。
  - 根据使用的刷盘策略，AOF的速度可能比RDB慢。
  - 因为个别命令的原因，导致AOF文件在重新载入后，无法将数据集恢复到之前的样子。
- **为什么采用写后日志**
  - 不需要检查命令是否语法错误
  - 不会阻塞当前写操作
  - 在命令执行完成，写入AOF之前系统宕机了，会丢失这段时间的数据。
  - 主线程写磁盘压力大，导致写盘慢，阻塞后续操作。

### 混合持久化的实现原理、优缺点
- 混合持久化并不是一种全新的持久化方式，而是对已有方式的优化。混合持久化只发生于AOF重写过程。使用了混合持久化，重写后的AOF文件前半段是RDB格式的全量数据，后半段是AOF格式的增量数据。
- 优点：结合了RDB和AOF的优点，更快的重写和恢复。
- 缺点：AOF文件里面的RDB不是不再是AOF格式，可读性差。


### AOF重写
#### 为什么需要AOF重写
- AOF是通过保存被执行的写命令来记录数据库状态的，随着被执行的命令越来越多，文件体积越来越大，如果不加以控制，体积过大的AOF文件会对Redis服务器、甚至整个宿主机造成影响。并且随着AOF体积的越来越大，恢复数据的时间也会越来越长。

#### AOF重写
- Redis生成新的AOF文件来替换旧的文件，这个新的AOF文件包含了恢复数据的最少命令集合。具体的过程就是遍历数据库的所有键，从数据库读取现在的值，然后用一条命令去记录键值对，代替之前记录这个键值对的多条命令。(BGREWRITEOF，REWRITEOF)

#### AOF后台重写存在的问题
- 子进程在进行AOF重写期间，主进程还需要继续处理命令请求，新的命令可能会对现有的数据库状态进行修改，导致当前的数据库状态和重写后的AOF的数据库状态不一致。


#### 如何解决AOF后台重写存在的数据不一致问题
- 引入AOF重写缓冲区，这个缓冲区在创建子线程之后开始使用，当Redis服务器执行读命令后，它会将这个读命令同时追加到**AOF缓冲区和AOF重写缓冲区**。当子线程完成AOF重写后，父进程会将AOF重写缓冲区的内容写入到新的AOF文件中，并对新的AOF文件进行改名，完成新旧文件的替换。这样主进程就能继续接收命令请求了。

#### AOF重写缓冲区内容过多怎么办
- 因为AOF重写缓冲区的内容追加到新的AOF文件是由主线程完成的，所以当重写缓冲区文件太大时，会造成一段时间的阻塞，这显然是不能接受的。
- 解决方案：在进行AOF后台重写时，**Redis会创建一组用于父子进程间通信的通道，同时会新增一个文件事件**，该文件事件会将写入AOF重写缓冲区的内容通过该管道发送到子进程。在重写结束后，子进程会通过该管道尽量从父进程读取更多的数据。如果连续20次没有读取到则结束这个过程。
#### 主线程fork出子进程是如何复制内存数据的？
- 拷贝父进程的页表，即虚实映射关系(虚拟内存到物理内存的映射索引表)

#### 在重写日志整个过程中，主线程有哪些地方会被阻塞？
- fork子进程的时候，需要拷贝虚拟页表，会对主线程阻塞。
- 主进程有bigkey写入时，操作系统会创建页面的副本，并拷贝原有的数据，会对主线程阻塞。
- 子进程重写完日志后，主进程追加AOF重写缓冲区内容时可能会对主进程阻塞。

#### 为什么AOF重写不复用原AOF日志？
- 父子进程间写同一文件会产生竞争问题，影响父进程的性能。
- 如果AOF重写过程中失败了，相当于污染了原本的AOF文件，无法做恢复数据使用。


### RDB、AOF、混合持久，我应该用哪一个
- 如果想尽量保证数据安全性，应该同时使用RDB和AOF持久化功能。如果能够接受分钟内的丢失，可以使用RDB，如果你的数据可以丢失的，可以关闭持久化功能。
#### 从持久化中恢复数据
- redis重启时判断是否开启aof，如果开启了aof，那么优先加载aof文件
- 如果aof文件存在，就去加载aof文件。如果aof文件加载失败，就会打印日志，此时可以去修复aof文件后重新启动。如果加载成功则重启成功。
- 如果aof文件不存在，则转去加载rdb文件，如果rdb文件不存在，redis直接启动成功。
- 如果rdb文件存在就去加载rdb文件恢复数据，如果加载失败提示启动失败。如果加载成功，则重启成功，并使用rdb文件恢复数据。

### 性能与实践 

---

## 消息传递

---

## 事件机制

### aeEventLoop


#### 事件的调度与执行

### 文件事件
#### Redis的事件处理器
- 由4部分组成：套接字、I/O多路复用程序、文件事件分派器以及事件处理器
- 套接字：socket连接，也就是客户端连接。当一个套接字准备好执行连接、写入、读取、关闭等操作时，就会产生一个相应的文件事件。因为一个服务器可能连接多个套接字，所以多个文件事件有可能并发地出现。
- I/O多路复用程序：提供select、epoll、evport、kqueue的实现，会根据当前系统自动选择最佳的方式。负责监听多个套接字，当套接字产生事件后，会向文件事件分派器传送那些产生了事件的套接字。
- 当多个文件事件并发的出现时，I/O多路复用程序会将所有产生事件的套接字都放到一个队列里，然后通过这个队列有序、同步、每次以一个套接字的方式向文件事件分派器传送套接字：当上一个套接字产生的事件被处理完毕后，才会继续传送下一个套接字。
- 文件事件分派器：接收I/O多路复用程序传来的套接字，并根据套接字产生的事件类型，调用相应的事件处理器。
- 事件处理器：就是一个个函数，定一个某个事件发生时，服务器应该执行的动作。例如：建立连接、命令查询、命令写入、连接关闭等。

### 时间事件

### Reactor模式

---

## Redis事务

### 什么是Redis事务
Redis事务本质上是一组命令的集合。事务支持一次执行多个命令，一个事物中所有命令都会被序列化。在事务执行过程中，会按照顺序串行执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行的命令序列中。

### CAS操作实现乐观锁
- WATCH可以为Redis事务提供CAS行为。
- Redis使用WATCH命令来决定事务是继续执行或者是回滚。在MULTI命令之前WATCH某些键值对，然后使用MULTI开启事务，执行对数据结构的各种命令，将这些命令入队。当执行EXEC时，会比较WATCH监控的键值对是否变化，没有发生变化执行队列中的命令，发生变化不执行队列中的命令，事务回滚。无论是否回滚，Redis都会取消事务执行前的WATCH命令。

### Redis事务执行步骤
- 开启：使用MULTI命令开启事务。
- 入队：将多个命令入队到事务中，这些命令不会立即执行，而是加入到等待执行的事务队列里面。
- 执行：有EXEC命令触发事务。

### Redis为什么不支持回滚
- Redis命令只会对错误的语法导致的失败或者是命令用到了错误类型的键上，这些错误是变成错误造成的，应该在开发过程中被发现，而不是应该出现在生产环境中。
- 不需要对回滚进行支持，Redis内部保持简单和快捷。

### 如何理解Redis与事务的ACID？
- ACID：原子性、一致性、隔离性、持久性

---

## Redis主从复制

### 主从复制的作用
- 数据冗余
- 故障恢复
- 负载均衡：主服务器提供写服务，从服务器提供读服务，用于读多写少的环境。
- 高可用基石

主从库之间采用读写分离的方式：
- 读操作：主服务器和从服务器都可以接收
- 写操作：首先在主服务器执行，接着主库将写操作同步给从服务器。

### 主从复制实现原理

1. 开启主从复制
    - 命令：replicaof \<masterip> \<masterport> 或者 配置文件 replicaof \<masterip> \<masterport>
2. 建立套接字连接
    - slave根据ip和端口向master发送套接字连接，master在接受套接字连接后，创建相应的客户端状态。
3. 发送PING命令
    - slave发送ping命令，以检查套接字的读写状态是否正常。
4. 身份验证
    - 如果master和slave都设置密码，则验证，都没有设置密码则不需要验证，一个设置一个不设置返回错误。
5. 发送端口信息
    - slave向master发送自己的监听端口，master收到后记录在slave所对应的客户端状态的slave_listening_port属性中。
6. 发送IP地址
    - slave向master发送slave_announce_ip配置的ip地址，master收到记录后记录在slave所对应的客户端状态的slave_ip属性。
7. 发送CAPA
    - slave发送capa告诉master自己的同步复制能力，master收到后记录在slave对应的客户端状态的slave_capa属性。
8. 数据同步
    - slave向master发送PSYNC命令，master收到该命令后判断是进行部分重同步还是完整重同步，然后根据策略进行数据的同步。
    - slave如果是第一次执行复制，会发送PSYNC ？ -1，master返回+FULLRESYNC \<replid> \<offset>执行完整重同步。
    - 如果不是第一次执行，slave则发送PSYNC replid offset，其中replid是master的复制ID，offset是slave当前的复制偏移量。master根据replid和offset来判断应该执行哪种同步操作。如果是完整重同步，返回+FULLRESYNC \<replid> \<offset>；如果是部分重同步，则返回+CONTINUE \<replid>，此时slave只需要等待master将自己缺少的数据发送过来就可以了。
9. 命令传播
    - 当完成了同步之后，就进入命令传播阶段，master会将自己执行的写命令一直发送给slave，slave负责一直接收命令。这样就能保证master和slave的一致性了。
    - 在命令传播阶段，slave默认每秒一次的频率向master发送命令：REPLCONF ACK \<reploff>。
    - 发送REPLCONF有三个作用：1. 检测master与slave之间的网络状态。2. 汇报自己的偏移量，检测命令丢失。3. 辅助实现min-slaves配置，用于防止master在不安全的情况下执行命令。


### 旧版同步：SYNC
- Redis2.8之前的数据同步通过SYNC命令来实现
- slave向master发送SYNC命令，master收到命令后执行BGSAVE命令，fork子进程生成RDB文件，同时会有一个缓冲区记录当前开始所有的写命令。当BGSAVE执行完成后，master将生成的RDB文件发送给slave，slave接收RDB文件并载入到内存，将数据库状态更新到master执行BGSAVE之前的状态。当master进行命令传播时，将缓冲区中的写命令发送给slave，还会同时写进复制积压缓冲区。当slave重连上master时，会将自己的复制偏移量通过PSYNC发送给master，master通过与复制积压缓冲区进行比较，如果发现部分未同步的命令还在复制积压缓冲区，则将这部分命令进行部分同步，如果重连时间太久，这部分命令已经不在复制积压缓冲区，则将进行全同步。


### 运行ID(runid)
- 每个Redis Server都会有自己的运行ID，当slave初次复制master时，master会将自己的runid发送给slave进行保存，之后slave再次进行复制的时候就会讲该runid发送给master，master通过比较runid来判断是不是同一个master。
- 引入runid后，数据同步过程变为slave通过PSYNC runid offset命令，将正在复制的runid和offset发送给master，master判断runid与自己的runid是否相等，如果相等，并且offset还在复制积压缓冲区，进行部分重同步。否则，如果runid不想等或者offset已经不在复制积压缓冲区，执行完全重同步。


### PSYNC存在的问题
- slave重启，runid和offset都会丢失，需要进行完全重同步。
- redis发生故障切换，故障切换后master runid发生了变化，slave需要进行完全重同步。

### PSYNC2
- 引入两组replid和offset替换原来的runid和offset
1. 第一组replid和offset，对于master来说，表示为自己的复制ID和复制偏移量，对于slave来说，表示为自己正在同步的master的复制ID和复制偏移量。
2. 第二组replid和offset，对于master和slave来说，都表示为自己上一个master的复制ID来复制偏移量；主要用于切换时支持部分重同步。
- slave也会开启复制积压缓冲区，主要用于故障切换后，slave代替master，该slave仍可以通过复制积压缓冲区来继续支持部分重同步，否则无法支持部分重同步。

### PSYNC2优化场景
1. slave重启后导致完整同步，原因是重启后复制ID和复制偏移量都丢失了，解决方法在关闭服务器之前将这两个变量存下来。
2. master故障切换后导致完整重同步：原因是master发生故障后，出现了新的master，而新的master的复制ID也发生了变化，导致无法进行部分重同步。解决方法，将新的复制ID和复制偏移量与老的复制ID和复制偏移量串联起来。slave在晋升为master后，将自己保存的第一组复制ID和偏移量移动到第二组，第一组生成属于自己的复制ID。这样新master通过第二组id判断slave是否是自己之前的master，如果是尝试进行部分重同步。

### 主从复制会存在哪些问题
- 一旦主节点宕机，从节点晋升为主节点，同时需要修改应用方的主节点地址，还需要命令所有从节点去复制新的主节点，整个过程需要人工干预。
- 主节点的写能力/存储能力受到单机的限制。

### 当主服务器不进行持久化时复制的安全性
- 主从复制的时候，主服务器应该开启持久化，当不能这么做时，必须考虑到延迟的问题，应该将实例配置为避免自动重启。

### 为什么主从全量复制使用RDB而不使用AOF？
1. RDB文件是经过压缩的二进制数据，文件很小。而AOF文件记录的是每一个写操作的命令，写操作越多文件就会变得越大，其中还包括多次对同一个key的荣誉操作。在主从全量数据同步的时候，传输RDB可以尽量降低对主库网络带宽的消耗。二是因为RDB文件是二进制数据，从库从库读取数据会很快，而AOF需要每次重放写命令，恢复速度相比RDB慢很多。
2. 假如使用AOF做全量复制，意味着必须打开AOF功能，如果使用不当可能会对Redis服务器的性能造成影响。而RDB只需要在需要定时备份和主从全量复制数据时才会触发一次快照，而在很多丢失数据不敏感的场景中，不需要打开AOF。
### 为什么还有无磁盘复制模式？
主服务器的子进程直接将RDB通过网络发送给从服务器，不通过磁盘作为中间存储。
### 为什么还有从库的从库设计？
- 发生一次主从复制服务器需要fork子进程，生成RDB文件，发送RDB文件，十分消耗性能和网络资源，如果很多从服务器进行主从复制会给主服务器带来很大压力。采用主-从-从的设计，在部署主从集群的时候，可以手动选择一个从库，用于级联其他的从库。然后可以再选择一些从库让他们和之前选的从库建立起主从关系。
### 读写分离及其中的问题
- 读写不一致的问题
- 数据过期问题：惰性删除和定期删除
- 故障切换问题
---

## Redis哨兵机制

### 哨兵
- 主从复制存在的问题可以用哨兵机制来解决。使用Sentinel来完成节点选举工作。
- 哨兵用于监控Redis集群中Master主服务器的工作状态，可以完成Master和Slave的主从转换。

#### 系统可以执行四个任务：
1. 监控：不断检查主服务器和从服务器是否正常运行。
2. 通知：当被监控的某个Redis服务器出现问题，Sentinel通过API脚本向管理员或其他应用发出通知。
3. 自动故障转移：当主节点不能正常工作时，Sentinel会开始一次自动的故障转移。会将失效主节点的从节点中选择一个成为主节点，并将其他从节点指向新的主节点。
4. 配置提供者：在Redis Sentinel模式下，客户端应用在初始化的时候是与Sentinel节点集合连接，从而获取主节点信息。

#### 哨兵集群的组建


#### 哨兵监控Redis库

#### 哨兵的选举机制

#### 工作原理：
1. 每个Sentinel节点每秒一次的频率向它所知的主服务器，从服务器以及其他Sentinel节点发送PING命令
2. 当一个实例距离有效恢复PING命令的有效时间超过down-after-milliseconds所指定的值时，该Sentinel节点标记为主观下线。
3. 如果一个主服务器被标记为主观下线后，那么正在监视的其他Sentinel节点也要以每秒一次的频率确认主服务进入了主观下线状态。
4. 这时有足够数量的Sentinel节点在指定的时间范围内确认该服务器处于主观下线状态，主服务器被标记为客观下线状态。
5. 一般情况下每个Sentinel以每十秒一次的频率向主服务器和从服务器发送INFO命令，当一个主服务器被指定为客观下线时，频率会改为一秒一次。
6. Sentinel协商客观下线的主节点的状态，如果处于SDOWN状态，则投票出新的主节点，并将从节点指向新的主节点进行数据复制。
7. 如果没有足够数量的Sentinel同意主节点下线，则主节点的客观下线状态被移除。当主服务器重新向Sentinel命令有效回复时，主服务器的主观下线状态被移除。


---

## 缓存

### 缓存穿透
- 大量请求的数据根本不在缓存和数据库中，导致大量请求不经过缓存，直接到了数据库，失去了缓存的意义。
- 解决方案：
    1. 参数校验：一些不合法的请求直接抛出异常返回给服务器。
    2. 缓存无效key，当缓存和数据库都不存在该key的数据时，在Redis中写入该key，并设置一定的过期时间。这种方式适合变化不频繁的key的情况。如果key变化频繁会导致Redis中存在大量无效的key。
    3. 布隆过滤器：可以非常方便的判断一个给定的数据是否存在于海量数据中。具体做法是把所有可能存在的请求的值放到过滤器中，用户请求过来的事情，首先判断用户发来的请求的值是否存在于过滤器中，如果不存在直接返回异常结果给客户端。

### 缓存击穿
- 缓存中没有但数据库中有的数据(一般是缓存时间到期)，这时由于并发用户特别多，同时读缓存没有读到数据，又同时去数据库取数据，引起数据库压力瞬间增大，造成过大压力。
- 解决方案：
    1. 设置热点数据永不过期
    2. **接口限流与熔断，降级**。重要的接口一定要做好限流策略，防止用户恶意刷接口，同时要降级准备，当接口中的某些服务不可用时，进行熔断，失败快速返回机制。
    3. 加互斥锁。

### 缓存雪崩
- 缓存在同一时间内大面积的失效，导致大量的用户请求直接到了数据库，造成数据库短时间内承受大量的请求。
- 解决方案：
    - 针对Redis服务不可用的情况：(1)设置Redis集群，避免单机出现问题导致整个缓存服务都没办法使用。(2)限流，避免同时处理大量请求。
    - 针对热点缓存失效问题：(1)随机设置热点缓存失效时间.(2)热点数据永不失效。

### 缓存污染
- 缓存中一些只被访问一次或者几次的数据，被访问后再也不会被访问到，但这部分数据依然在缓存中，消耗缓存空间。
- 缓存空间是有限的，如果缓存空间满了，再往缓存里写数据时就会有额外的开销，影响Redis的性能。这部分额外性能消耗主要是指写的时候判断淘汰策略，根据淘汰策略去选择要淘汰的数据，然后进行删除操作。

#### 最大缓存设置多大
- 设置为总数据量的15%到30%，兼顾访问性能和内存空间开销。

#### Redis删除过期键的策略(缓存失效策略、数据过期策略)
- 定时删除：在设置键的过期事件的同时，创建一个定时器，让定时器在键的过期时间来临时，立即执行对键的删除操作。对内存最友好，对cpu时间最不友好。
- 惰性删除：每次获取键时，都会检查键是否过期，如果过期就删除键；如果没有过期就返回该键。对CPU时间最优化，对内存最不友好。
- 定期删除：每个一段时间，默认100ms，程序就会对数据库进行一次检查，删除里面的过期键。至于要删除多少过期键，以及要检查多少数据库由算法决定。前两种策略的折中，对cpu时间和内存的友好程度较平衡。
- Redis使用惰性删除和定期删除。

#### Redis的内存驱逐(淘汰)策略
- 当redis的内存空间已经用满时，就会根据配置的驱逐策略，进行相应的动作
- 有以下8中：
    1. 默认策略，不淘汰任何key，返回错误
    2. 在所有key中使用LRU算法淘汰部分key
    3. 在所有key中使用LFU算法淘汰部分key
    4. 在所有key中随机淘汰部分key
    5. 在设置了过期时间的key中，使用LRU算法淘汰部分key
    6. 在设置了过期时间的key中，使用LFU算法淘汰部分key
    7. 在设置了过期时间的key中，随机淘汰部分key
    8. 在设置了过期时间的key中，挑选TTL短的key淘汰


#### 数据库和缓存的一致性问题
不管先写数据库再删缓存还是先删缓存再写数据库，都可能会造成数据不一致的问题。
1. 当写数据库再删缓存时，当写完数据库，写进程的服务器突然宕机了，没有删掉缓存。
2. 当先删缓存时，一个线程还没来得及写数据库，另一个线程来读缓存，发现没有，去读数据库，并更新缓存，这时候写数据库的进程已经把缓存更新了，又更新回了久的，读到了脏数据。

#### 缓存的三种策略
- Cache Aside Pattern 旁路缓存模式
- Read/Write through Pattern 读写穿透模式
- Write behind Pattern 异步缓存写入


#### 旁路缓存模式(Cached Aside Pattern)
- 写：先更新DB，然后直接**失效缓存**
- 读：查询缓存，如果缓存存在，返回结果。如果缓存中不存在，读取DB，返回结果，并把返回的结果写入Cache
- 无论先操作数据库还是先操作缓存，都会存在脏数据的情况。

#### 读写穿透模式(Read/Write Through Pattern)
- 在旁路缓存模式下，应用层去和缓存和数据库打交道，增加了应用层的复杂度，在读写穿透模式下，应用层之和缓存打交道，由缓存去操作和维护数据库。
- 写：读取缓存，(1)缓存未命中，缓存去更新数据库，数据库返回结果，缓存返回更新成功。(2)缓存命中，更新缓存，缓存更新数据库，数据库返回结果，缓存返回更新成功。
- 读：读取缓存，(1)缓存命中，返回结果。(2)缓存未命中，缓存去查询数据库，写入缓存，缓存返回结果。

#### 异步缓存写入模式(Write Behind Caching Pattern)
- 读写穿透模式每次更新数据都回去同时写入数据库，数据写入速度会比较慢。
- 异步缓存写入模式会在一段时间之后异步的将数据批量写入数据库。优点：(1)应用层只写缓存，速度快。(2)缓存在异步的写入数据库的时候会将多个I/O操作合并为一个，减少I/O次数。
- 缺点：复杂度高，更新后的数据如果没写入数据库，遇到断电问题会导致数据丢失。


#### 如何保证数据库与缓存的一致性
- 可以引入分布式事务来解决，常见的有：2PC、TCC、MQ事务消息等。但是引入分布式事务，会带来性能上的影响。
- 在实际的使用中，通常不会去保证cache和DB的强一致性，而是允许两者在短暂时间内的不一致，保证两者的最终一致性。
- 最终一致性的常用方案如下：(1)更新数据库，数据库产生binlog，监听和消费binlog，执行实现缓存操作。如果失效缓存失败，引入重试机制，将失败的数据通过MQ的方式进行重试。

#### 异步更新缓存(基于订阅binlog的同步机制)
1. 读Redis：热数据基本都在Redis
2. 写数据库：增删改都在操作MySQL
3. 更新Redis数据：MySQL的数据更新binlog，来更新Redis
4. Redis增量更新。订阅binlog，读取分析后，对Redis进行更新。


## Memcached VS Redis

### 共同点
1. 都是基于内存的数据库，一般都用来当作缓存使用
2. 都有过期策略
3. 两个性能都很高

### 区别
1. Redis支持更丰富的数据结构
2. Redis支持数据的持久化
3. Redis有灾难恢复机制
4. Redis在服务器内存用完之后，可以将不用的数据放到磁盘上
5. Memcached没有原生的集群模式
6. Redis使用单线程的多路IO复用模型
7. Redis支持订阅模型
8. Redis过期数据使用了惰性删除和定期删除